{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from utils.transforms import *\n",
    "from utils.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physionet = PhysionetDataset(train=True)\n",
    "slp = SLPDataset(train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "- Basic normalization\n",
    "  - normalize values between 0 and 1 because images from the different datasets have different value ranges in the images\n",
    "  - equalizeHist to have a unified brightness and contrast\n",
    "  - normalize mean because it normalizes statistical properties of the images and is a recommended and often used step\n",
    "  - same for standardization\n",
    "- warum diese reihenfolge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.Compose(\n",
    "    [\n",
    "        Resize((32, 64)),\n",
    "        Standardize(),\n",
    "        NormalizeValues(),\n",
    "        EqualizeHist(),\n",
    "    ]\n",
    "),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agressive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.Compose(\n",
    "    [\n",
    "        Resize((32, 64)),\n",
    "        Standardize(),\n",
    "        NormalizeValues(),\n",
    "        EqualizeHist(),\n",
    "        Blur((3, 3)),\n",
    "        Threshold(lambda img: np.median(img[img > 0.0])),\n",
    "    ]\n",
    "),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.Compose(\n",
    "    [\n",
    "        Resize((32, 64)),\n",
    "        Standardize(),\n",
    "        NormalizeValues(),\n",
    "        EqualizeHist(),\n",
    "        Blur((3, 3)),\n",
    "        Threshold(lambda img: np.median(img[img > 0.0])),\n",
    "        Sobel(),\n",
    "        Threshold(lambda img: np.median(img[img > 0.0])),\n",
    "    ]\n",
    "),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling Ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(\n",
    "    samples,\n",
    "    ncols=10,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            *normalizations,\n",
    "            RollingBall(radius=5),\n",
    "            Blur((3, 3)),\n",
    "            Threshold(lambda img: np.median(img[img > 0.0])),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(\n",
    "    samples,\n",
    "    ncols=10,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            *normalizations,\n",
    "            Denoise(),\n",
    "            Blur((3, 3)),\n",
    "            HighPass(rad=50),\n",
    "            Blur((3, 3)),\n",
    "            Threshold(lambda img: np.median(img[img > 0.0])),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving SLP\n",
    "\n",
    "- hier zwei szenarien testen: einmal diese transformation auf beide datensätze anwenden und einmal nur auf slp und agressive thresholding oder so auf physionet\n",
    "- interessante sache: später resizen behält in den schritten davor noch mehr details, womit besser preprocessed werden kann\n",
    "- Potential: Menschen auf slp bildern vergrößern, damit die auf allen druckbildern ungefähr gleich groß sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.Compose(\n",
    "    [\n",
    "        Standardize(),\n",
    "        NormalizeValues(),\n",
    "        EqualizeHist(),\n",
    "        Blur((3, 3)),\n",
    "        Denoise(),\n",
    "        Threshold(lambda img: np.median(img[img > 0.0])),\n",
    "        Close((3, 3), ktype=cv2.MORPH_CROSS, iterations=3),\n",
    "        Blur((3, 3)),\n",
    "        Resize((32, 64)),\n",
    "    ]\n",
    "),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physionet_zca = deepcopy(physionet)\n",
    "slp_zca = deepcopy(slp)\n",
    "physionet_zca.x = zca(physionet_zca.x, epsilon=0.1)\n",
    "slp_zca.x = np.load(\"./data/SLP/data_zca.npy\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1570699ba4f120b96ddfd0503318136b734b0558b028e188e1a2824f4937ee21"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
